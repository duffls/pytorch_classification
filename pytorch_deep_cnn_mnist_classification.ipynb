{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c5807e",
   "metadata": {},
   "source": [
    "## Pytorch Model\n",
    "## 깊은 신경망을 이용한 classification 문제 해결\n",
    "\n",
    "## 첫번째 레이어의 형태\n",
    "- 합성곱 (in_channel=1, out_channel=32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "- 맥스풀링 (kernel_size=2, stride=2)\n",
    "\n",
    "## 두번째 레이어의 형태\n",
    "- 합성곱 (in_channel=32, out_channel=64, kernel_size=3, stride=1, padding=1), 활성화 함수 ReLU\n",
    "- 맥스풀링 (kernel_size=2, stride=2)\n",
    "\n",
    "## 세번째 레이어의 형태\n",
    "- 합성곱 (in_channel=64, out_channel=128, kernel_size=3, stride=1, padding=1), 활성화 함수 ReLU\n",
    "- 맥스풀링 (kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "## 네번째 레이어의 형태\n",
    "- 특성맴을 펼치는 역할\n",
    "- FC layer + ReLU\n",
    "\n",
    "## 다섯번째 레이어, 전결합층(FC layer)\n",
    "- FC layer + Softmax\n",
    "- 마지막노드는 10개, 0~9까지의 정답을 가져야 하기 때문에 노드를 10개 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f2cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5717bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드를 고정\n",
    "torch.manual_seed(777)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b410d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "learning_rate = 0.001\n",
    "training_epochs = 300\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f914917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더를 사용 데이터셋을 정의\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7cb8ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더로 배치크기 지정.\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n",
    "# 60,000개 데이터가 batch_size(100)의 크기로 진행, total batch는 600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18f0a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스로 모델을 설계\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        \n",
    "        # 첫번째 레이어\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 두번째 레이어\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 세번째 레이어\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # 레이어\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "        # 레이어\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "        # 레이어\n",
    "        self.layer6 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # 네번째 레이어        \n",
    "        self.fc1 = torch.nn.Linear(2 * 2 * 1024, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer7 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p =1 - self.keep_prob))\n",
    "        \n",
    "        # 다섯번째 레이어\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #print(\"1 \", out.shape)\n",
    "        out = self.layer4(out)\n",
    "        #print(\"1 \", out.shape)\n",
    "        out = self.layer5(out)\n",
    "        #print(\"1 \", out.shape)\n",
    "        out = self.layer6(out)\n",
    "        #print(\"1 \", out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.layer7(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65efb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcc610d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수와 옵티마이저\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eea211cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    }
   ],
   "source": [
    "# 총 배치의 수\n",
    "total_batch = len(data_loader)\n",
    "print(f\"총 배치의 수 : {total_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4488c2f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1 cost = 0.311792344]\n",
      "[Epoch:    2 cost = 0.0624712184]\n",
      "[Epoch:    3 cost = 0.0467354208]\n",
      "[Epoch:    4 cost = 0.0385017432]\n",
      "[Epoch:    5 cost = 0.0339843705]\n",
      "[Epoch:    6 cost = 0.027999457]\n",
      "[Epoch:    7 cost = 0.0227896422]\n",
      "[Epoch:    8 cost = 0.0245058723]\n",
      "[Epoch:    9 cost = 0.0207136758]\n",
      "[Epoch:   10 cost = 0.0177859198]\n",
      "[Epoch:   11 cost = 0.0184923578]\n",
      "[Epoch:   12 cost = 0.0157412142]\n",
      "[Epoch:   13 cost = 0.0174020417]\n",
      "[Epoch:   14 cost = 0.0143661248]\n",
      "[Epoch:   15 cost = 0.0125211375]\n",
      "[Epoch:   16 cost = 0.0154184159]\n",
      "[Epoch:   17 cost = 0.011474085]\n",
      "[Epoch:   18 cost = 0.0139781758]\n",
      "[Epoch:   19 cost = 0.00933977123]\n",
      "[Epoch:   20 cost = 0.010161506]\n",
      "[Epoch:   21 cost = 0.0112072602]\n",
      "[Epoch:   22 cost = 0.012212188]\n",
      "[Epoch:   23 cost = 0.00864262134]\n",
      "[Epoch:   24 cost = 0.0140828146]\n",
      "[Epoch:   25 cost = 0.0133043518]\n",
      "[Epoch:   26 cost = 0.00792987272]\n",
      "[Epoch:   27 cost = 0.00621376699]\n",
      "[Epoch:   28 cost = 0.00858408678]\n",
      "[Epoch:   29 cost = 0.00877747592]\n",
      "[Epoch:   30 cost = 0.0104030333]\n",
      "[Epoch:   31 cost = 0.00733211171]\n",
      "[Epoch:   32 cost = 0.0044671772]\n",
      "[Epoch:   33 cost = 0.00706016645]\n",
      "[Epoch:   34 cost = 0.0112308338]\n",
      "[Epoch:   35 cost = 0.00533858221]\n",
      "[Epoch:   36 cost = 0.00762583409]\n",
      "[Epoch:   37 cost = 0.00970056653]\n",
      "[Epoch:   38 cost = 0.0127270008]\n",
      "[Epoch:   39 cost = 0.00670543453]\n",
      "[Epoch:   40 cost = 0.00703860773]\n",
      "[Epoch:   41 cost = 0.00860825833]\n",
      "[Epoch:   42 cost = 0.0045376136]\n",
      "[Epoch:   43 cost = 0.00896014646]\n",
      "[Epoch:   44 cost = 0.00626105536]\n",
      "[Epoch:   45 cost = 0.00554274302]\n",
      "[Epoch:   46 cost = 0.0109842476]\n",
      "[Epoch:   47 cost = 0.00974091608]\n",
      "[Epoch:   48 cost = 0.00407528877]\n",
      "[Epoch:   49 cost = 0.00398763828]\n",
      "[Epoch:   50 cost = 0.00531850755]\n",
      "[Epoch:   51 cost = 0.0115245776]\n",
      "[Epoch:   52 cost = 0.00647549331]\n",
      "[Epoch:   53 cost = 0.00450961106]\n",
      "[Epoch:   54 cost = 0.00821174867]\n",
      "[Epoch:   55 cost = 0.0106142825]\n",
      "[Epoch:   56 cost = 0.00364851253]\n",
      "[Epoch:   57 cost = 0.00397297228]\n",
      "[Epoch:   58 cost = 0.00940163806]\n",
      "[Epoch:   59 cost = 0.00567356497]\n",
      "[Epoch:   60 cost = 0.0060836398]\n",
      "[Epoch:   61 cost = 0.000946581946]\n",
      "[Epoch:   62 cost = 0.00143885578]\n",
      "[Epoch:   63 cost = 0.00921003241]\n",
      "[Epoch:   64 cost = 0.00647655176]\n",
      "[Epoch:   65 cost = 0.00316597777]\n",
      "[Epoch:   66 cost = 0.012776969]\n",
      "[Epoch:   67 cost = 0.00405503716]\n",
      "[Epoch:   68 cost = 0.00491348747]\n",
      "[Epoch:   69 cost = 0.000600655272]\n",
      "[Epoch:   70 cost = 0.00907737855]\n",
      "[Epoch:   71 cost = 0.00366002787]\n",
      "[Epoch:   72 cost = 0.00350233028]\n",
      "[Epoch:   73 cost = 0.00968853291]\n",
      "[Epoch:   74 cost = 0.0062973802]\n",
      "[Epoch:   75 cost = 0.00403063465]\n",
      "[Epoch:   76 cost = 0.0162964929]\n",
      "[Epoch:   77 cost = 0.00352769601]\n",
      "[Epoch:   78 cost = 0.00678876974]\n",
      "[Epoch:   79 cost = 0.00347352237]\n",
      "[Epoch:   80 cost = 0.00418996438]\n",
      "[Epoch:   81 cost = 0.0063036806]\n",
      "[Epoch:   82 cost = 0.00639534416]\n",
      "[Epoch:   83 cost = 0.00255990052]\n",
      "[Epoch:   84 cost = 0.00812853593]\n",
      "[Epoch:   85 cost = 0.00531424629]\n",
      "[Epoch:   86 cost = 0.00709850946]\n",
      "[Epoch:   87 cost = 0.00233538519]\n",
      "[Epoch:   88 cost = 0.00867986865]\n",
      "[Epoch:   89 cost = 0.00440386636]\n",
      "[Epoch:   90 cost = 0.00376947527]\n",
      "[Epoch:   91 cost = 0.011649156]\n",
      "[Epoch:   92 cost = 0.00401793467]\n",
      "[Epoch:   93 cost = 0.00117983029]\n",
      "[Epoch:   94 cost = 0.00660949899]\n",
      "[Epoch:   95 cost = 0.00577178085]\n",
      "[Epoch:   96 cost = 0.00111627567]\n",
      "[Epoch:   97 cost = 0.0105904043]\n",
      "[Epoch:   98 cost = 0.000692282745]\n",
      "[Epoch:   99 cost = 0.0102732601]\n",
      "[Epoch:  100 cost = 0.00263897236]\n",
      "[Epoch:  101 cost = 0.00895519555]\n",
      "[Epoch:  102 cost = 0.0199209042]\n",
      "[Epoch:  103 cost = 0.0047108382]\n",
      "[Epoch:  104 cost = 0.00332461344]\n",
      "[Epoch:  105 cost = 0.00401345175]\n",
      "[Epoch:  106 cost = 0.0152271977]\n",
      "[Epoch:  107 cost = 0.0035923114]\n",
      "[Epoch:  108 cost = 0.00372949359]\n",
      "[Epoch:  109 cost = 0.00202709856]\n",
      "[Epoch:  110 cost = 0.00982675981]\n",
      "[Epoch:  111 cost = 0.0165149458]\n",
      "[Epoch:  112 cost = 0.00509837316]\n",
      "[Epoch:  113 cost = 0.000372061273]\n",
      "[Epoch:  114 cost = 7.01553581e-05]\n",
      "[Epoch:  115 cost = 0.00027815692]\n",
      "[Epoch:  116 cost = 0.0178267844]\n",
      "[Epoch:  117 cost = 0.00565693201]\n",
      "[Epoch:  118 cost = 0.00211970834]\n",
      "[Epoch:  119 cost = 0.00410266407]\n",
      "[Epoch:  120 cost = 0.00788164698]\n",
      "[Epoch:  121 cost = 0.00559193967]\n",
      "[Epoch:  122 cost = 0.00229269406]\n",
      "[Epoch:  123 cost = 0.00210668426]\n",
      "[Epoch:  124 cost = 0.00532760564]\n",
      "[Epoch:  125 cost = 0.00943335611]\n",
      "[Epoch:  126 cost = 0.00840559881]\n",
      "[Epoch:  127 cost = 0.00385360839]\n",
      "[Epoch:  128 cost = 0.00355898193]\n",
      "[Epoch:  129 cost = 0.00199369667]\n",
      "[Epoch:  130 cost = 0.0120573984]\n",
      "[Epoch:  131 cost = 0.00484545343]\n",
      "[Epoch:  132 cost = 0.00049369398]\n",
      "[Epoch:  133 cost = 0.00903751049]\n",
      "[Epoch:  134 cost = 0.00276229018]\n",
      "[Epoch:  135 cost = 0.00391563401]\n",
      "[Epoch:  136 cost = 0.0162072368]\n",
      "[Epoch:  137 cost = 0.00508321449]\n",
      "[Epoch:  138 cost = 0.00452668918]\n",
      "[Epoch:  139 cost = 0.0106559955]\n",
      "[Epoch:  140 cost = 0.0112023]\n",
      "[Epoch:  141 cost = 0.00441825995]\n",
      "[Epoch:  142 cost = 0.00017172574]\n",
      "[Epoch:  143 cost = 1.98737034e-05]\n",
      "[Epoch:  144 cost = 5.78864274e-05]\n",
      "[Epoch:  145 cost = 0.0166436415]\n",
      "[Epoch:  146 cost = 0.0127904816]\n",
      "[Epoch:  147 cost = 0.00587512227]\n",
      "[Epoch:  148 cost = 0.00600028969]\n",
      "[Epoch:  149 cost = 0.00450855168]\n",
      "[Epoch:  150 cost = 0.0153099755]\n",
      "[Epoch:  151 cost = 0.00243467954]\n",
      "[Epoch:  152 cost = 0.000443739671]\n",
      "[Epoch:  153 cost = 0.00334943226]\n",
      "[Epoch:  154 cost = 0.00807527546]\n",
      "[Epoch:  155 cost = 0.0148043018]\n",
      "[Epoch:  156 cost = 0.00306389085]\n",
      "[Epoch:  157 cost = 0.000181699914]\n",
      "[Epoch:  158 cost = 0.00939464942]\n",
      "[Epoch:  159 cost = 0.00136867072]\n",
      "[Epoch:  160 cost = 5.3132866e-05]\n",
      "[Epoch:  161 cost = 7.76636716e-06]\n",
      "[Epoch:  162 cost = 8.56850056e-06]\n",
      "[Epoch:  163 cost = 1.51283007e-06]\n",
      "[Epoch:  164 cost = 0.0257210284]\n",
      "[Epoch:  165 cost = 0.0101368278]\n",
      "[Epoch:  166 cost = 0.0015788395]\n",
      "[Epoch:  167 cost = 5.43129026e-05]\n",
      "[Epoch:  168 cost = 0.00984224863]\n",
      "[Epoch:  169 cost = 0.0141037516]\n",
      "[Epoch:  170 cost = 0.00726623926]\n",
      "[Epoch:  171 cost = 0.00209406135]\n",
      "[Epoch:  172 cost = 0.00219441345]\n",
      "[Epoch:  173 cost = 0.00787483528]\n",
      "[Epoch:  174 cost = 0.0038661838]\n",
      "[Epoch:  175 cost = 0.00729304692]\n",
      "[Epoch:  176 cost = 0.0122519648]\n",
      "[Epoch:  177 cost = 0.0136010936]\n",
      "[Epoch:  178 cost = 0.00158193032]\n",
      "[Epoch:  179 cost = 0.00241259113]\n",
      "[Epoch:  180 cost = 0.00456177723]\n",
      "[Epoch:  181 cost = 0.0110703334]\n",
      "[Epoch:  182 cost = 0.00771446247]\n",
      "[Epoch:  183 cost = 0.010824075]\n",
      "[Epoch:  184 cost = 0.00201900932]\n",
      "[Epoch:  185 cost = 0.00115269609]\n",
      "[Epoch:  186 cost = 0.000588299707]\n",
      "[Epoch:  187 cost = 0.0121677006]\n",
      "[Epoch:  188 cost = 0.00891985931]\n",
      "[Epoch:  189 cost = 0.00751842931]\n",
      "[Epoch:  190 cost = 0.00066081871]\n",
      "[Epoch:  191 cost = 0.0136156939]\n",
      "[Epoch:  192 cost = 0.00541668851]\n",
      "[Epoch:  193 cost = 0.00416479725]\n",
      "[Epoch:  194 cost = 0.000298528787]\n",
      "[Epoch:  195 cost = 0.00149532442]\n",
      "[Epoch:  196 cost = 0.009106935]\n",
      "[Epoch:  197 cost = 0.00612687366]\n",
      "[Epoch:  198 cost = 0.0186818335]\n",
      "[Epoch:  199 cost = 0.00715898443]\n",
      "[Epoch:  200 cost = 0.00379852299]\n",
      "[Epoch:  201 cost = 0.00148076308]\n",
      "[Epoch:  202 cost = 0.000382156461]\n",
      "[Epoch:  203 cost = 0.000127920255]\n",
      "[Epoch:  204 cost = 0.0162926912]\n",
      "[Epoch:  205 cost = 0.0112104546]\n",
      "[Epoch:  206 cost = 0.0093192691]\n",
      "[Epoch:  207 cost = 0.0130244251]\n",
      "[Epoch:  208 cost = 0.00424772967]\n",
      "[Epoch:  209 cost = 0.00566647248]\n",
      "[Epoch:  210 cost = 0.00162817771]\n",
      "[Epoch:  211 cost = 6.44708416e-05]\n",
      "[Epoch:  212 cost = 2.13753174e-05]\n",
      "[Epoch:  213 cost = 1.21191842e-05]\n",
      "[Epoch:  214 cost = 7.07854924e-05]\n",
      "[Epoch:  215 cost = 0.0180022158]\n",
      "[Epoch:  216 cost = 0.00692709163]\n",
      "[Epoch:  217 cost = 0.0169030428]\n",
      "[Epoch:  218 cost = 0.0137989735]\n",
      "[Epoch:  219 cost = 0.0128559694]\n",
      "[Epoch:  220 cost = 0.00200365903]\n",
      "[Epoch:  221 cost = 0.00204068306]\n",
      "[Epoch:  222 cost = 0.0211529937]\n",
      "[Epoch:  223 cost = 0.0079509858]\n",
      "[Epoch:  224 cost = 0.00207487261]\n",
      "[Epoch:  225 cost = 0.00346663245]\n",
      "[Epoch:  226 cost = 0.00877922308]\n",
      "[Epoch:  227 cost = 0.0101750242]\n",
      "[Epoch:  228 cost = 0.00911902729]\n",
      "[Epoch:  229 cost = 0.00709089311]\n",
      "[Epoch:  230 cost = 0.00481635192]\n",
      "[Epoch:  231 cost = 0.0174344946]\n",
      "[Epoch:  232 cost = 0.00224061799]\n",
      "[Epoch:  233 cost = 0.00160520314]\n",
      "[Epoch:  234 cost = 0.000145743048]\n",
      "[Epoch:  235 cost = 0.0163914394]\n",
      "[Epoch:  236 cost = 0.0130909011]\n",
      "[Epoch:  237 cost = 0.000362414808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:  238 cost = 0.00022518661]\n",
      "[Epoch:  239 cost = 0.00236316468]\n",
      "[Epoch:  240 cost = 0.0163228624]\n",
      "[Epoch:  241 cost = 0.010365027]\n",
      "[Epoch:  242 cost = 0.00408769213]\n",
      "[Epoch:  243 cost = 0.00613998948]\n",
      "[Epoch:  244 cost = 0.00138716085]\n",
      "[Epoch:  245 cost = 0.000256380852]\n",
      "[Epoch:  246 cost = 0.000403667247]\n",
      "[Epoch:  247 cost = 0.00453624083]\n",
      "[Epoch:  248 cost = 0.00564843277]\n",
      "[Epoch:  249 cost = 0.0117666014]\n",
      "[Epoch:  250 cost = 0.00918870885]\n",
      "[Epoch:  251 cost = 0.00407671323]\n",
      "[Epoch:  252 cost = 0.000109777473]\n",
      "[Epoch:  253 cost = 3.18888924e-05]\n",
      "[Epoch:  254 cost = 2.25009135e-05]\n",
      "[Epoch:  255 cost = 0.0151305338]\n",
      "[Epoch:  256 cost = 0.00891306903]\n",
      "[Epoch:  257 cost = 0.0020707841]\n",
      "[Epoch:  258 cost = 0.0418311246]\n",
      "[Epoch:  259 cost = 0.00175866263]\n",
      "[Epoch:  260 cost = 0.000758318463]\n",
      "[Epoch:  261 cost = 0.0010927096]\n",
      "[Epoch:  262 cost = 0.00857369229]\n",
      "[Epoch:  263 cost = 0.000962837716]\n",
      "[Epoch:  264 cost = 0.00556645636]\n",
      "[Epoch:  265 cost = 0.0133139975]\n",
      "[Epoch:  266 cost = 0.0262801629]\n",
      "[Epoch:  267 cost = 0.000746450853]\n",
      "[Epoch:  268 cost = 0.00355270086]\n",
      "[Epoch:  269 cost = 0.0163762271]\n",
      "[Epoch:  270 cost = 0.00520513672]\n",
      "[Epoch:  271 cost = 0.00218285481]\n",
      "[Epoch:  272 cost = 0.0001111495]\n",
      "[Epoch:  273 cost = 0.0114446646]\n",
      "[Epoch:  274 cost = 0.019589385]\n",
      "[Epoch:  275 cost = 0.00536422851]\n",
      "[Epoch:  276 cost = 0.00326637668]\n",
      "[Epoch:  277 cost = 8.16606698e-05]\n",
      "[Epoch:  278 cost = 3.69624213e-05]\n",
      "[Epoch:  279 cost = 2.1917469e-05]\n",
      "[Epoch:  280 cost = 4.5710849e-06]\n",
      "[Epoch:  281 cost = 6.94345727e-06]\n",
      "[Epoch:  282 cost = 1.27868236e-06]\n",
      "[Epoch:  283 cost = 2.54129827e-06]\n",
      "[Epoch:  284 cost = 5.27502925e-06]\n",
      "[Epoch:  285 cost = 1.29060948e-06]\n",
      "[Epoch:  286 cost = 1.22156086e-06]\n",
      "[Epoch:  287 cost = 0.0346091054]\n",
      "[Epoch:  288 cost = 0.0297071971]\n",
      "[Epoch:  289 cost = 0.00379148731]\n",
      "[Epoch:  290 cost = 0.00372148864]\n",
      "[Epoch:  291 cost = 0.00607583672]\n",
      "[Epoch:  292 cost = 0.0121131567]\n",
      "[Epoch:  293 cost = 0.00879841764]\n",
      "[Epoch:  294 cost = 0.00272929179]\n",
      "[Epoch:  295 cost = 0.00053460151]\n",
      "[Epoch:  296 cost = 0.000310156407]\n",
      "[Epoch:  297 cost = 0.000161162054]\n",
      "[Epoch:  298 cost = 0.00036271385]\n",
      "[Epoch:  299 cost = 0.0523473993]\n",
      "[Epoch:  300 cost = 0.00897155888]\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print(f\"[Epoch: {epoch+1:>4} cost = {avg_cost:>.9}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2450d648",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75409996509552\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(f\"Accuracy: {accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c3fcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc360d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f02a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266ed30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a5cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec758e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb68840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af239f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce19c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b57b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e86f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8087a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b675905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914fd86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
