{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f29e529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 10:20:52,906 - INFO - icrawler.crawler - start crawling...\n",
      "2022-02-15 10:20:52,906 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2022-02-15 10:20:52,906 - INFO - feeder - thread feeder-001 exit\n",
      "2022-02-15 10:20:52,906 - INFO - icrawler.crawler - starting 2 parser threads...\n",
      "2022-02-15 10:20:52,914 - INFO - icrawler.crawler - starting 4 downloader threads...\n",
      "2022-02-15 10:20:54,138 - INFO - parser - parsing result page https://www.google.com/search?q=car+crash&ijn=1&start=100&tbs=&tbm=isch\n",
      "2022-02-15 10:20:54,169 - INFO - downloader - skip downloading file 000001.jpg\n",
      "2022-02-15 10:20:54,169 - INFO - downloader - skip downloading file 000002.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000003.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000004.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000005.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000006.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000007.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000008.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000009.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000010.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000011.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000012.jpg\n",
      "2022-02-15 10:20:54,184 - INFO - downloader - skip downloading file 000013.jpg\n",
      "2022-02-15 10:20:54,192 - INFO - downloader - skip downloading file 000014.jpg\n",
      "2022-02-15 10:20:54,192 - INFO - downloader - skip downloading file 000015.jpg\n",
      "2022-02-15 10:20:54,192 - INFO - downloader - skip downloading file 000016.jpg\n",
      "2022-02-15 10:20:54,193 - INFO - downloader - skip downloading file 000017.jpg\n",
      "2022-02-15 10:20:54,193 - INFO - downloader - skip downloading file 000018.jpg\n",
      "2022-02-15 10:20:54,194 - INFO - downloader - skip downloading file 000019.jpg\n",
      "2022-02-15 10:20:54,194 - INFO - downloader - skip downloading file 000020.jpg\n",
      "2022-02-15 10:20:54,195 - INFO - downloader - skip downloading file 000021.jpg\n",
      "2022-02-15 10:20:54,195 - INFO - downloader - skip downloading file 000022.jpg\n",
      "2022-02-15 10:20:54,196 - INFO - downloader - skip downloading file 000023.jpg\n",
      "2022-02-15 10:20:54,196 - INFO - downloader - skip downloading file 000024.jpg\n",
      "2022-02-15 10:20:54,197 - INFO - downloader - skip downloading file 000025.jpg\n",
      "2022-02-15 10:20:54,197 - INFO - downloader - skip downloading file 000026.jpg\n",
      "2022-02-15 10:20:54,198 - INFO - downloader - skip downloading file 000027.jpg\n",
      "2022-02-15 10:20:54,200 - INFO - downloader - skip downloading file 000028.jpg\n",
      "2022-02-15 10:20:54,200 - INFO - downloader - skip downloading file 000029.jpg\n",
      "2022-02-15 10:20:54,201 - INFO - downloader - skip downloading file 000030.jpg\n",
      "2022-02-15 10:20:54,201 - INFO - downloader - skip downloading file 000031.jpg\n",
      "2022-02-15 10:20:54,202 - INFO - downloader - skip downloading file 000032.jpg\n",
      "2022-02-15 10:20:54,202 - INFO - downloader - skip downloading file 000033.jpg\n",
      "2022-02-15 10:20:54,204 - INFO - downloader - skip downloading file 000034.jpg\n",
      "2022-02-15 10:20:54,205 - INFO - downloader - skip downloading file 000035.jpg\n",
      "2022-02-15 10:20:54,206 - INFO - downloader - skip downloading file 000036.jpg\n",
      "2022-02-15 10:20:54,206 - INFO - downloader - skip downloading file 000037.jpg\n",
      "2022-02-15 10:20:54,206 - INFO - downloader - skip downloading file 000038.png\n",
      "2022-02-15 10:20:54,207 - INFO - downloader - skip downloading file 000039.jpg\n",
      "2022-02-15 10:20:54,207 - INFO - downloader - skip downloading file 000040.jpg\n",
      "2022-02-15 10:20:54,208 - INFO - downloader - skip downloading file 000041.jpg\n",
      "2022-02-15 10:20:54,208 - INFO - downloader - skip downloading file 000042.jpg\n",
      "2022-02-15 10:20:54,209 - INFO - downloader - skip downloading file 000043.jpg\n",
      "2022-02-15 10:20:54,209 - INFO - downloader - skip downloading file 000044.jpg\n",
      "2022-02-15 10:20:54,210 - INFO - downloader - skip downloading file 000045.jpg\n",
      "2022-02-15 10:20:54,210 - INFO - downloader - skip downloading file 000046.jpg\n",
      "2022-02-15 10:20:54,211 - INFO - downloader - skip downloading file 000047.jpg\n",
      "2022-02-15 10:20:54,211 - INFO - downloader - skip downloading file 000048.jpg\n",
      "2022-02-15 10:20:54,212 - INFO - downloader - skip downloading file 000049.jpg\n",
      "2022-02-15 10:20:54,212 - INFO - downloader - skip downloading file 000050.jpg\n",
      "2022-02-15 10:20:54,212 - INFO - downloader - skip downloading file 000051.jpg\n",
      "2022-02-15 10:20:54,213 - INFO - downloader - skip downloading file 000052.jpg\n",
      "2022-02-15 10:20:54,213 - INFO - downloader - skip downloading file 000053.jpg\n",
      "2022-02-15 10:20:54,214 - INFO - downloader - skip downloading file 000054.jpg\n",
      "2022-02-15 10:20:54,214 - INFO - downloader - skip downloading file 000055.jpg\n",
      "2022-02-15 10:20:54,215 - INFO - downloader - skip downloading file 000056.jpg\n",
      "2022-02-15 10:20:54,215 - INFO - downloader - skip downloading file 000057.jpg\n",
      "2022-02-15 10:20:54,216 - INFO - downloader - skip downloading file 000058.jpg\n",
      "2022-02-15 10:20:54,216 - INFO - downloader - skip downloading file 000059.jpg\n",
      "2022-02-15 10:20:54,217 - INFO - downloader - skip downloading file 000060.jpg\n",
      "2022-02-15 10:20:54,217 - INFO - downloader - skip downloading file 000061.jpg\n",
      "2022-02-15 10:20:54,218 - INFO - parser - parsing result page https://www.google.com/search?q=car+crash&ijn=0&start=0&tbs=&tbm=isch\n",
      "2022-02-15 10:20:54,219 - INFO - downloader - skip downloading file 000062.jpg\n",
      "2022-02-15 10:20:54,221 - INFO - downloader - skip downloading file 000063.jpg\n",
      "2022-02-15 10:20:54,222 - INFO - downloader - skip downloading file 000064.jpg\n",
      "2022-02-15 10:20:54,223 - INFO - downloader - skip downloading file 000065.jpg\n",
      "2022-02-15 10:20:54,223 - INFO - downloader - skip downloading file 000066.jpg\n",
      "2022-02-15 10:20:54,224 - INFO - downloader - skip downloading file 000067.jpg\n",
      "2022-02-15 10:20:54,225 - INFO - downloader - skip downloading file 000068.jpg\n",
      "2022-02-15 10:20:54,226 - INFO - downloader - skip downloading file 000069.jpg\n",
      "2022-02-15 10:20:54,227 - INFO - downloader - skip downloading file 000070.jpg\n",
      "2022-02-15 10:20:54,227 - INFO - downloader - skip downloading file 000071.jpg\n",
      "2022-02-15 10:20:54,227 - INFO - downloader - skip downloading file 000072.jpg\n",
      "2022-02-15 10:20:54,228 - INFO - downloader - skip downloading file 000073.jpg\n",
      "2022-02-15 10:20:54,228 - INFO - downloader - skip downloading file 000074.jpg\n",
      "2022-02-15 10:20:54,229 - INFO - downloader - skip downloading file 000075.jpg\n",
      "2022-02-15 10:20:54,229 - INFO - downloader - skip downloading file 000076.jpg\n",
      "2022-02-15 10:20:54,229 - INFO - downloader - skip downloading file 000077.jpg\n",
      "2022-02-15 10:20:54,230 - INFO - downloader - skip downloading file 000078.jpg\n",
      "2022-02-15 10:20:54,231 - INFO - downloader - skip downloading file 000079.jpg\n",
      "2022-02-15 10:20:54,232 - INFO - downloader - skip downloading file 000080.jpg\n",
      "2022-02-15 10:20:54,232 - INFO - downloader - skip downloading file 000081.jpg\n",
      "2022-02-15 10:20:54,233 - INFO - downloader - skip downloading file 000082.jpg\n",
      "2022-02-15 10:20:54,233 - INFO - downloader - skip downloading file 000083.jpg\n",
      "2022-02-15 10:20:54,234 - INFO - downloader - skip downloading file 000084.jpg\n",
      "2022-02-15 10:20:54,234 - INFO - downloader - skip downloading file 000085.jpg\n",
      "2022-02-15 10:20:54,384 - INFO - downloader - image #86\thttps://res.cloudinary.com/graham-media-group/image/upload/f_auto/q_auto/c_scale,w_400/v1/media/gmg/7TZSC3DQLNGRVN5F6WBLAUNBO4.png\n",
      "2022-02-15 10:20:54,895 - INFO - parser - parsing result page https://www.google.com/search?q=car+crash&ijn=2&start=200&tbs=&tbm=isch\n",
      "2022-02-15 10:20:54,923 - INFO - parser - parsing result page https://www.google.com/search?q=car+crash&ijn=3&start=300&tbs=&tbm=isch\n",
      "2022-02-15 10:20:55,110 - ERROR - downloader - Response status code 401, file https://i.guim.co.uk/img/media/077f02391691f02dc5415770b802e4c96d1bde36/0_0_2670_1602/master/2670.jpg\n",
      "2022-02-15 10:20:55,213 - INFO - downloader - image #87\thttps://images.7news.com.au/publication/C-4928407/d4839eb625da5a9661cb6f46d136283c09b9c63c-16x9-x0y0w1920h1080.jpg\n",
      "2022-02-15 10:20:55,366 - INFO - downloader - image #88\thttps://media.wusa9.com/assets/WUSA/images/5394f347-0546-4c64-a724-a02a848d67bf/5394f347-0546-4c64-a724-a02a848d67bf_1920x1080.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 10:20:55,486 - ERROR - downloader - Response status code 403, file https://www.chicagotribune.com/resizer/_nmtVmAoiNKfblN0GD2487Cp6fQ\\u003d/1200x0/top/cloudfront-us-east-1.images.arcpublishing.com/tronc/GNV5574VDZCDXMAPQH6UHNC6II.jpg\n",
      "2022-02-15 10:20:55,805 - INFO - parser - parsing result page https://www.google.com/search?q=car+crash&ijn=4&start=400&tbs=&tbm=isch\n",
      "2022-02-15 10:20:56,989 - INFO - parser - no more page urls for thread parser-001 to parse\n",
      "2022-02-15 10:20:56,991 - INFO - parser - thread parser-001 exit\n",
      "2022-02-15 10:20:57,291 - INFO - downloader - image #89\thttps://i2-prod.dailyrecord.co.uk/news/scottish-news/article26212003.ece/ALTERNATES/s1200c/0_Screen-Shot-2022-02-12-at-112352.png\n",
      "2022-02-15 10:20:57,849 - INFO - parser - no more page urls for thread parser-002 to parse\n",
      "2022-02-15 10:20:57,849 - INFO - parser - thread parser-002 exit\n",
      "2022-02-15 10:21:00,224 - INFO - downloader - no more download task for thread downloader-002\n",
      "2022-02-15 10:21:00,225 - INFO - downloader - thread downloader-002 exit\n",
      "2022-02-15 10:21:00,379 - INFO - downloader - no more download task for thread downloader-001\n",
      "2022-02-15 10:21:00,381 - INFO - downloader - thread downloader-001 exit\n",
      "2022-02-15 10:21:00,487 - INFO - downloader - no more download task for thread downloader-003\n",
      "2022-02-15 10:21:00,488 - INFO - downloader - thread downloader-003 exit\n",
      "2022-02-15 10:21:02,304 - INFO - downloader - no more download task for thread downloader-004\n",
      "2022-02-15 10:21:02,304 - INFO - downloader - thread downloader-004 exit\n",
      "2022-02-15 10:21:02,980 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    }
   ],
   "source": [
    "# 사고데이터 수집\n",
    "# 데이터 크롤링을  사용해 데이터셋을만들고, 이미지로 학습하는 모델\n",
    "from icrawler.builtin import GoogleImageCrawler\n",
    "\n",
    "google_crawler = GoogleImageCrawler(parser_threads=2, downloader_threads=4, storage={'root_dir': './data'})\n",
    "\n",
    "google_crawler.crawl(keyword = 'car crash', max_num=500, min_size=(200, 200), max_size=(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0930ce51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " [[[100 119 107]\n",
      "  [ 98 118 106]\n",
      "  [ 97 115 103]\n",
      "  ...\n",
      "  [171 166 163]\n",
      "  [168 163 160]\n",
      "  [171 167 164]]\n",
      "\n",
      " [[ 94 116 103]\n",
      "  [ 97 117 105]\n",
      "  [ 98 117 101]\n",
      "  ...\n",
      "  [171 166 163]\n",
      "  [180 175 171]\n",
      "  [169 165 160]]\n",
      "\n",
      " [[ 91 113  98]\n",
      "  [ 94 117  97]\n",
      "  [ 93 116  95]\n",
      "  ...\n",
      "  [168 163 158]\n",
      "  [170 166 153]\n",
      "  [172 168 159]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[174 159 152]\n",
      "  [161 149 137]\n",
      "  [171 158 146]\n",
      "  ...\n",
      "  [ 93  93  99]\n",
      "  [ 97  96  97]\n",
      "  [ 76  77  81]]\n",
      "\n",
      " [[169 157 148]\n",
      "  [166 156 150]\n",
      "  [142 133 121]\n",
      "  ...\n",
      "  [142 146 161]\n",
      "  [142 143 154]\n",
      "  [127 130 150]]\n",
      "\n",
      " [[154 141 137]\n",
      "  [158 144 140]\n",
      "  [158 144 138]\n",
      "  ...\n",
      "  [133 134 151]\n",
      "  [142 147 165]\n",
      "  [143 154 175]]]\n",
      "0 \n",
      " [[[ 34  34  34]\n",
      "  [ 38  36  36]\n",
      "  [ 75  58  43]\n",
      "  ...\n",
      "  [ 39  36  38]\n",
      "  [ 52  50  52]\n",
      "  [ 33  30  32]]\n",
      "\n",
      " [[ 33  33  33]\n",
      "  [ 35  31  30]\n",
      "  [ 51  45  40]\n",
      "  ...\n",
      "  [ 58  55  57]\n",
      "  [ 57  55  57]\n",
      "  [ 44  41  42]]\n",
      "\n",
      " [[ 35  35  34]\n",
      "  [ 37  37  36]\n",
      "  [ 41  41  41]\n",
      "  ...\n",
      "  [ 62  57  60]\n",
      "  [ 53  49  51]\n",
      "  [ 51  50  51]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[149 141 136]\n",
      "  [153 144 139]\n",
      "  [157 147 143]\n",
      "  ...\n",
      "  [155 152 153]\n",
      "  [150 148 149]\n",
      "  [145 143 143]]\n",
      "\n",
      " [[151 142 138]\n",
      "  [153 144 140]\n",
      "  [160 151 146]\n",
      "  ...\n",
      "  [159 157 158]\n",
      "  [154 152 152]\n",
      "  [146 145 145]]\n",
      "\n",
      " [[136 129 128]\n",
      "  [138 131 129]\n",
      "  [145 138 134]\n",
      "  ...\n",
      "  [209 209 210]\n",
      "  [195 195 197]\n",
      "  [187 188 189]]]\n",
      "0 \n",
      " [[[ 15  15  16]\n",
      "  [ 15  15  17]\n",
      "  [ 16  16  17]\n",
      "  ...\n",
      "  [ 27  19  24]\n",
      "  [ 29  20  25]\n",
      "  [ 27  19  23]]\n",
      "\n",
      " [[ 14  14  16]\n",
      "  [ 14  14  16]\n",
      "  [ 16  16  17]\n",
      "  ...\n",
      "  [ 31  21  25]\n",
      "  [ 33  23  27]\n",
      "  [ 29  21  25]]\n",
      "\n",
      " [[ 14  14  16]\n",
      "  [ 16  16  17]\n",
      "  [ 16  16  18]\n",
      "  ...\n",
      "  [ 34  23  26]\n",
      "  [ 37  25  29]\n",
      "  [ 33  23  27]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[109 109 110]\n",
      "  [104 104 105]\n",
      "  [ 99  99  99]\n",
      "  ...\n",
      "  [103 103 101]\n",
      "  [114 105  99]\n",
      "  [ 93  91  88]]\n",
      "\n",
      " [[108 109 110]\n",
      "  [107 107 108]\n",
      "  [107 107 107]\n",
      "  ...\n",
      "  [123 113 108]\n",
      "  [111 105 106]\n",
      "  [135 110 114]]\n",
      "\n",
      " [[112 112 113]\n",
      "  [107 107 108]\n",
      "  [109 109 110]\n",
      "  ...\n",
      "  [186 145 148]\n",
      "  [176 158 161]\n",
      "  [196 148 153]]]\n",
      "0 \n",
      " [[[ 52  55  25]\n",
      "  [ 70  70  38]\n",
      "  [ 48  50  22]\n",
      "  ...\n",
      "  [167 103  83]\n",
      "  [173 108  88]\n",
      "  [122  77  66]]\n",
      "\n",
      " [[ 51  56  24]\n",
      "  [ 55  56  29]\n",
      "  [ 52  53  27]\n",
      "  ...\n",
      "  [168 104  84]\n",
      "  [166 104  85]\n",
      "  [165 101  81]]\n",
      "\n",
      " [[ 44  48  19]\n",
      "  [ 53  61  25]\n",
      "  [ 96  94  73]\n",
      "  ...\n",
      "  [171 103  82]\n",
      "  [176 106  83]\n",
      "  [120  72  61]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[147 137 142]\n",
      "  [147 137 143]\n",
      "  [148 137 143]\n",
      "  ...\n",
      "  [168 156 164]\n",
      "  [166 153 162]\n",
      "  [169 158 165]]\n",
      "\n",
      " [[142 132 138]\n",
      "  [140 129 134]\n",
      "  [144 132 136]\n",
      "  ...\n",
      "  [163 151 159]\n",
      "  [160 147 156]\n",
      "  [163 151 160]]\n",
      "\n",
      " [[135 124 128]\n",
      "  [136 123 127]\n",
      "  [146 130 131]\n",
      "  ...\n",
      "  [161 150 159]\n",
      "  [156 144 152]\n",
      "  [174 163 170]]]\n",
      ">>> data 저장중...\n",
      "ok 7\n"
     ]
    }
   ],
   "source": [
    "# 수집한 데이터를 이미지 처리 및 t/t set 으로 나누는 과정\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 분류 대상 카테고리 선택하기 \n",
    "accident_dir = \"./image\"\n",
    "categories = [\"Car front crash\",\"Car side crash\",\"Rear and crash\",\"Car broken windshield\",\"Car scratch\",\"Flat tire\",\"Overturned vehicle\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 \n",
    "image_w = 64 \n",
    "image_h = 64\n",
    "pixels = image_w * image_h * 3\n",
    "\n",
    "# 이미지 데이터 읽어 들이기 \n",
    "X = []\n",
    "Y = []\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정 \n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "    \n",
    "    # 이미지 \n",
    "    image_dir = accident_dir + \"/\" + cat\n",
    "    #image_dir = (r\"C:\\anaconda\\keras\\data\")\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f) \n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)      # numpy 배열로 변환\n",
    "        X.append(data)\n",
    "        Y.append(label)\n",
    "        if i % 10 == 0:\n",
    "            print(i, \"\\n\", data)\n",
    "        #print(f\"{i}:{label}\")\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "# 학습 전용 데이터와 테스트 전용 데이터 구분 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\">>> data 저장중...\")\n",
    "np.save(\"./image/7obj.npy\", xy)\n",
    "print(\"ok\", len(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26d66b80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5, 64, 64, 3)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               7373312   \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 7)                 3591      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 7,433,223\n",
      "Trainable params: 7,433,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7945 - accuracy: 0.6000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5044 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3554 - accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8541 - accuracy: 0.6000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2954 - accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9586 - accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.6000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# CNN Model (keras)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#카테고리 \n",
    "categories = [\"Car front crash\",\n",
    "              \"Car side crash\",\n",
    "              \"Rear and crash\",\n",
    "              \"Car broken windsheid\",\n",
    "              \"Car scratch\",\n",
    "              \"Flat tire\",\n",
    "              \"Overturned vehicle\"]\n",
    "\n",
    "nb_classes = len(categories)\n",
    "\n",
    "img_w = 64\n",
    "img_h = 64\n",
    "X_train, X_test, y_train, y_test = np.load('./image/7obj.npy', allow_pickle=True)\n",
    "\n",
    "#데이터 정규화\n",
    "X_train = X_train.astype(\"float\")/256\n",
    "X_test = X_test.astype('float')/256\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "\n",
    "# 모델 구조 정의\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# FC\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 모델 구축, keras. compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 확인 \n",
    "print(model.summary())\n",
    "\n",
    "hdf5_file = \"./7obj-model.hdf5\"\n",
    "if os.path.exists(hdf5_file):\n",
    "    model.load_weights(hdf5_file)\n",
    "else:\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=10)\n",
    "    model.save_weights(hdf5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db6d1171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step - loss: 3.2084 - accuracy: 0.5000\n",
      "loss= 3.2084479331970215\n",
      "accuracy= 0.5\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca8fae87",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/000001.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-a301ba108b56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#적용시킬 이밎 선택\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./data/000001.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RGB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2974\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2975\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/000001.jpg'"
     ]
    }
   ],
   "source": [
    "#적용시킬 이밎 선택\n",
    "test_image = './data/000001.jpg'\n",
    "img = Image.open(test_image)\n",
    "img = img.convert(\"RGB\")\n",
    "img = img.resize((64,64))\n",
    "data = np.array(img)\n",
    "X = np.array(data)\n",
    "X = X.astype(\"float\")/256\n",
    "X = X.reshape(-1, 64, 64, 3)\n",
    "\n",
    "# 예측\n",
    "pred = model.predict(X)\n",
    "result = [np.argmax(value) for value in pred]\n",
    "print(\"Data's Category is :\", categories[result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe8a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de92c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa4d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb70757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750960b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
